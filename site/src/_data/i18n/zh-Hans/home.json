{
  "meta": {
    "title": "l10n · 像发布软件一样做本地化",
    "description": "将本地化保留在仓库中，使用你的工具链验证，借助 LLM 草稿加速发布。"
  },
  "hero": {
    "badge": "开源 CLI 工具",
    "title": "为你的代码库打造的智能体本地化方案",
    "lead": "l10n 使用 LLM 翻译你的内容，所有文件保留在仓库中，本地验证输出，生成的草稿可供团队直接审核——无需在外部平台之间来回导入导出。",
    "cta_primary": "快速开始",
    "cta_secondary": "工作原理"
  },
  "origin": {
    "title": "为什么 Tuist 要做这个",
    "intro": {
      "prefix": "我们尝试过 ",
      "crowdin": "Crowdin",
      "middle": " 和 ",
      "weblate": "Weblate",
      "suffix": "。导入导出内容的间接流程拖慢了我们的节奏，而且无法在流程中运行自己的验证。我们想要的是和写代码一样的工作流：修改、测试、审核、发布。"
    },
    "note": "现在翻译直接在本地生成，由你的工具链检查，只在必要时才需要人工审核。"
  },
  "how": {
    "title": "工作原理",
    "steps": [
      {
        "number": "01",
        "title": "为智能体提供上下文",
        "text": "在内容旁边添加 L10N.md 上下文文件。l10n 会追踪它们的依赖关系，当上下文或内容变更时，只有受影响的翻译才会重新生成。"
      },
      {
        "number": "02",
        "title": "选择你的模型",
        "text": "选择一个模型来协调智能体会话，另一个负责精确翻译。支持任何 OpenAI 兼容端点、Vertex AI，或你自己托管的模型。"
      },
      {
        "number": "03",
        "title": "智能体自行验证输出",
        "text": "智能体可以使用内置的语法检查和你定义的自定义命令。每次翻译后它们会运行验证，出错时自动重试，确保输出在你审核之前就已正确。"
      }
    ]
  },
  "config": {
    "title": "配置就在你的仓库里",
    "l10n": {
      "title": "L10N.md",
      "text": "在 TOML frontmatter 中定义翻译来源、目标语言和输出模式。"
    },
    "cli": {
      "title": "CLI 命令",
      "text": "翻译、验证、追踪需要更新的内容。",
      "items": [
        {
          "cmd": "l10n init",
          "desc": "交互式项目初始化"
        },
        {
          "cmd": "l10n translate",
          "desc": "生成翻译"
        },
        {
          "cmd": "l10n status",
          "desc": "报告缺失或过期的输出"
        },
        {
          "cmd": "l10n check",
          "desc": "验证输出语法"
        },
        {
          "cmd": "l10n clean",
          "desc": "清理过期的翻译输出"
        }
      ],
      "note_prefix": "使用",
      "note_suffix": "可重新翻译全部内容。"
    }
  },
  "features": {
    "title": "为真实工作流而生",
    "items": [
      {
        "title": "上下文感知的哈希机制",
        "text": "当源内容或上级 L10N.md 上下文变更时，翻译会自动更新。"
      },
      {
        "title": "验证钩子",
        "text": "内置 JSON、YAML、PO 语法检查，可选配置外部 lint 命令。"
      },
      {
        "title": "智能体流水线",
        "text": "协调模型与翻译模型分离，验证出错时自动重试。"
      },
      {
        "title": "人工审核就绪",
        "text": "快速生成草稿，按需审核，所有内容保留在 Git 中。"
      }
    ]
  },
  "faq": {
    "title": "常见问题",
    "items": [
      {
        "q": "这和传统翻译工具有什么不同？",
        "a": "传统工具依赖翻译记忆库——一个通过相似度匹配历史翻译的静态数据库。l10n 用 LLM 上下文作为记忆来替代它：智能体读取并学习上下文文件，你的团队可以持续迭代这些文件。智能体不是去查找模糊匹配，而是理解你产品的语气、术语和惯例。就像开发者通过编译或 lint 验证代码变更一样，智能体使用你环境中相同的工具来验证翻译。无论在 CI 还是本地运行，智能体都会使用你的 linter、编译器和验证器来修正自己的输出。"
      },
      {
        "q": "需要自己准备模型吗？",
        "a": "是的。l10n 是一个 CLI 工具，不是托管服务。你需要指向任意 OpenAI 兼容端点、Vertex AI，或你自己的模型。成本、数据和质量都由你掌控。"
      },
      {
        "q": "人工如何审核翻译？",
        "a": "目前，审核者通过 pull request 和 diff 查看翻译内容，需要时可以更新上下文文件来触发重新翻译。未来，我们预期他们会成为流程的一部分，在本地运行 l10n——就像开发者现在使用 Codex 等编码智能体一样。"
      }
    ]
  },
  "updates": {
    "title": "动态"
  }
}