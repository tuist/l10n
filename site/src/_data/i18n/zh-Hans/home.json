{
  "meta": {
    "title": "l10n · 像发布软件一样做本地化",
    "description": "将本地化保留在仓库内，使用你的工具链进行验证，借助 LLM 草稿加速发布。"
  },
  "hero": {
    "badge": "开源 CLI 工具",
    "title": "为你的代码库打造的智能体本地化方案",
    "lead": "l10n 使用 LLM 翻译你的内容，所有文件保留在仓库内，在本地验证输出，生成供团队审核的草稿——无需在外部平台之间来回折腾。",
    "cta_primary": "快速开始",
    "cta_secondary": "工作原理"
  },
  "origin": {
    "title": "为什么 Tuist 要做这个",
    "intro": {
      "prefix": "我们试过 ",
      "crowdin": "Crowdin",
      "middle": " 和 ",
      "weblate": "Weblate",
      "suffix": "。导出导入内容的间接流程拖慢了我们的节奏，而且无法在流程中运行自己的验证。我们想要的是和写代码一样的工作流：修改、测试、审核、发布。"
    },
    "note": "现在翻译在本地生成，由你的工具链检查，只在必要时才需要人工审核。"
  },
  "how": {
    "title": "工作原理",
    "steps": [
      {
        "number": "01",
        "title": "为智能体提供上下文",
        "text": "在内容旁边添加 L10N.md 上下文文件。l10n 会追踪它们的依赖关系，当上下文或内容变化时，只重新生成受影响的翻译。"
      },
      {
        "number": "02",
        "title": "选择你的模型",
        "text": "选择一个模型协调智能体会话，另一个负责精准翻译。支持任何 OpenAI 兼容端点、Vertex AI 或你自己托管的模型。"
      },
      {
        "number": "03",
        "title": "智能体自行验证输出",
        "text": "智能体可以使用内置的语法检查和你定义的自定义命令。每次翻译后自动运行验证，出错则重试，确保输出在你审核前就是正确的。"
      }
    ]
  },
  "config": {
    "title": "配置就在你的仓库里",
    "l10n": {
      "title": "L10N.md",
      "text": "在 TOML frontmatter 中定义翻译源、目标语言和输出路径。"
    },
    "cli": {
      "title": "CLI 命令",
      "text": "翻译、验证、追踪待更新内容。",
      "items": [
        {
          "cmd": "l10n translate",
          "desc": "生成翻译"
        },
        {
          "cmd": "l10n status",
          "desc": "报告缺失或过时的输出"
        },
        {
          "cmd": "l10n check",
          "desc": "验证输出语法"
        },
        {
          "cmd": "l10n clean",
          "desc": "移除过时的翻译输出"
        }
      ],
      "note_prefix": "使用",
      "note_suffix": "重新翻译所有内容。"
    }
  },
  "features": {
    "title": "为真实工作流而生",
    "items": [
      {
        "title": "上下文感知的哈希机制",
        "text": "当源内容或上级 L10N.md 上下文变化时，翻译会自动更新。"
      },
      {
        "title": "验证钩子",
        "text": "内置 JSON、YAML、PO 语法检查，可选外部 lint 命令。"
      },
      {
        "title": "智能体流水线",
        "text": "协调模型和翻译模型分离，验证出错时自动重试。"
      },
      {
        "title": "随时可供人工审核",
        "text": "快速生成草稿，按需审核，所有内容保留在 Git 中。"
      }
    ]
  },
  "faq": {
    "title": "常见问题",
    "items": [
      {
        "q": "这和传统翻译工具有什么不同？",
        "a": "传统工具依赖翻译记忆库——一个通过相似度匹配的静态历史翻译数据库。l10n 用 LLM 上下文作为记忆来替代它：智能体会读取上下文文件并从中学习，你的团队也可以持续迭代这些文件。智能体不是去查找模糊匹配，而是理解你产品的语气、术语和规范。就像开发者通过编译或 lint 来验证代码变更一样，智能体使用你环境中的相同工具来验证翻译。无论在 CI 还是本地运行，智能体都会使用你的 linter、编译器和验证器来自动修正输出。"
      },
      {
        "q": "我需要自己提供模型吗？",
        "a": "是的。l10n 是一个 CLI 工具，不是托管服务。你可以将它指向任何 OpenAI 兼容端点、Vertex AI 或你自己的模型。成本、数据和质量都由你掌控。"
      },
      {
        "q": "人工如何审核翻译？",
        "a": "目前，审核者通过 Pull Request 和 diff 检查翻译内容，需要时可以更新上下文文件来触发重新翻译。未来，我们期望他们能通过在本地运行 l10n 加入到流程中——就像开发者现在使用 Codex 等编码智能体一样。"
      }
    ]
  },
  "updates": {
    "title": "更新动态"
  }
}