{
  "meta": {
    "title": "l10n · 像發布軟體一樣做本地化",
    "description": "將本地化保留在 repo 中，使用你的工具驗證，透過 LLM 草稿加速發布。"
  },
  "hero": {
    "badge": "開源 CLI 工具",
    "title": "為你的程式碼庫打造的 Agentic 本地化",
    "lead": "l10n 使用 LLM 翻譯你的內容，所有檔案保留在 repo 中，在本地驗證輸出，並產生草稿供團隊審閱——無需透過外部平台來回往返。",
    "cta_primary": "開始使用",
    "cta_secondary": "運作方式"
  },
  "origin": {
    "title": "為什麼 Tuist 要打造這個工具",
    "intro": {
      "prefix": "我們試過 ",
      "crowdin": "Crowdin",
      "middle": " 和 ",
      "weblate": "Weblate",
      "suffix": "。匯出匯入內容的間接流程拖慢了我們的速度，而且無法在流程中執行自己的驗證。我們想要和寫程式一樣的工作流程：修改、測試、審閱、發布。"
    },
    "note": "現在翻譯直接在原地產生，由你的工具檢查，只在必要時才由人工審閱。"
  },
  "how": {
    "title": "運作方式",
    "steps": [
      {
        "number": "01",
        "title": "為 agent 提供上下文",
        "text": "在內容旁邊加入 L10N.md 上下文檔案。l10n 會追蹤它們的依賴關係，當上下文或內容變更時，只有受影響的翻譯會重新產生。"
      },
      {
        "number": "02",
        "title": "選擇你的模型",
        "text": "選擇一個模型來協調 agentic session，另一個負責精準翻譯。支援任何 OpenAI 相容端點、Vertex AI，或你自己託管的模型。"
      },
      {
        "number": "03",
        "title": "Agent 自行驗證輸出",
        "text": "Agent 可以使用內建的語法檢查和你定義的自訂命令。它們會在每次翻譯後執行驗證，遇到錯誤時自動重試，確保輸出在你審閱前就是正確的。"
      }
    ]
  },
  "config": {
    "title": "設定存放在你的 repo 中",
    "l10n": {
      "title": "L10N.md",
      "text": "在 TOML frontmatter 中定義翻譯來源、目標語言和輸出路徑模式。"
    },
    "cli": {
      "title": "CLI 指令",
      "text": "翻譯、驗證，並追蹤需要更新的內容。",
      "items": [
        {
          "cmd": "l10n translate",
          "desc": "產生翻譯"
        },
        {
          "cmd": "l10n status",
          "desc": "報告缺少或過期的輸出"
        },
        {
          "cmd": "l10n check",
          "desc": "驗證輸出語法"
        },
        {
          "cmd": "l10n clean",
          "desc": "移除過時的翻譯輸出"
        }
      ],
      "note_prefix": "使用",
      "note_suffix": "來重新翻譯所有內容。"
    }
  },
  "features": {
    "title": "為實際工作流程打造",
    "items": [
      {
        "title": "上下文感知的雜湊機制",
        "text": "當來源內容或上層 L10N.md 上下文變更時，翻譯會自動更新。"
      },
      {
        "title": "驗證掛鉤",
        "text": "JSON、YAML 和 PO 語法檢查，以及可選的外部 lint 指令。"
      },
      {
        "title": "Agent 管線",
        "text": "分離的協調器和翻譯器模型，驗證錯誤時自動重試。"
      },
      {
        "title": "支援人工審閱",
        "text": "快速產生草稿，需要時再審閱，所有內容都保留在 Git 中。"
      }
    ]
  },
  "faq": {
    "title": "常見問題",
    "items": [
      {
        "q": "這和傳統翻譯工具有什麼不同？",
        "a": "傳統工具依賴翻譯記憶庫——透過相似度比對過去翻譯的靜態資料庫。l10n 用 LLM 上下文作為記憶取代它：agent 會讀取、學習上下文檔案，你的團隊可以隨時間迭代改進。agent 不是查找模糊比對，而是理解你產品的語氣、術語和慣例。就像開發者透過編譯或 linting 驗證程式碼變更一樣，agent 使用你環境中相同的工具驗證翻譯。無論在 CI 或本地執行，agent 都會使用你的 linter、編譯器和驗證器來修正自己的輸出。"
      },
      {
        "q": "我需要自己準備模型嗎？",
        "a": "是的。l10n 是 CLI 工具，不是託管服務。你可以指向任何 OpenAI 相容端點、Vertex AI，或你自己的模型。成本、資料和品質都由你掌控。"
      },
      {
        "q": "人工如何審閱翻譯？",
        "a": "目前，審閱者透過 pull request 和 diff 檢查翻譯內容，需要時可以更新上下文檔案來強制重新翻譯。未來，我們預期他們會成為流程的一部分，在本地執行 l10n——就像開發者現在使用 Codex 等 coding agent 一樣。"
      }
    ]
  },
  "updates": {
    "title": "更新"
  }
}