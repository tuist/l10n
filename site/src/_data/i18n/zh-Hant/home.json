{
  "meta": {
    "title": "l10n · 像發布軟體一樣做本地化",
    "description": "將本地化保留在 repo 中，使用你的工具驗證，透過 LLM 草稿加速交付。"
  },
  "hero": {
    "badge": "開源 CLI 工具",
    "title": "為你的 codebase 打造的 Agentic 本地化",
    "lead": "l10n 使用 LLM 翻譯內容，所有檔案保留在 repo 中，在本地驗證輸出，並產生草稿供團隊審閱，無需外部平台的來回往返。",
    "cta_primary": "開始使用",
    "cta_secondary": "運作原理"
  },
  "origin": {
    "title": "為什麼 Tuist 要開發這個工具",
    "intro": {
      "prefix": "我們試過 ",
      "crowdin": "Crowdin",
      "middle": " 和 ",
      "weblate": "Weblate",
      "suffix": "。匯出匯入內容的間接流程拖慢了我們的進度，而且無法在流程中執行自己的驗證。我們想要和寫程式一樣的工作流程：修改、測試、審閱、發布。"
    },
    "note": "現在翻譯直接在原地產生，由你的工具檢查，只在必要時才需人工審閱。"
  },
  "how": {
    "title": "運作原理",
    "steps": [
      {
        "number": "01",
        "title": "為 agent 提供上下文",
        "text": "在內容旁放置 L10N.md 上下文檔案。l10n 追蹤它們的依賴關係，當上下文或內容變更時，只重新產生受影響的翻譯。"
      },
      {
        "number": "02",
        "title": "選擇你的模型",
        "text": "選一個模型協調 agentic session，另一個模型負責精確翻譯。支援任何 OpenAI 相容端點、Vertex AI，或你自己託管的模型。"
      },
      {
        "number": "03",
        "title": "Agent 自行驗證成果",
        "text": "Agent 可使用內建語法檢查和你定義的自訂命令。每次翻譯後執行驗證，錯誤時自動重試，確保輸出在你審閱前就是正確的。"
      }
    ]
  },
  "tools": {
    "title": "工具",
    "intro": "Agent 使用工具在每次翻譯後自動驗證。",
    "categories": [
      {
        "title": "語法驗證器",
        "text": "解析輸出，確保儲存前格式有效。",
        "items": [
          "JSON",
          "YAML",
          "PO",
          "Markdown frontmatter"
        ]
      },
      {
        "title": "保留檢查",
        "text": "確保關鍵 token 在翻譯後保持完整。",
        "items": [
          "程式碼區塊",
          "行內程式碼",
          "URL",
          "佔位符"
        ]
      },
      {
        "title": "自訂命令",
        "text": "透過 check_cmd 和 check_cmds 使用你自己的驗證器。",
        "items": [
          "Linter",
          "編譯器",
          "Schema 驗證器"
        ]
      }
    ],
    "note": "工具失敗會觸發重試，直到輸出有效為止。"
  },
  "config": {
    "title": "設定檔保存在你的 repo 中",
    "l10n": {
      "title": "L10N.md",
      "text": "在 TOML frontmatter 中定義翻譯來源、目標和輸出路徑模式。"
    },
    "cli": {
      "title": "CLI 命令",
      "text": "翻譯、驗證、追蹤需要更新的內容。",
      "items": [
        {
          "cmd": "l10n init",
          "desc": "互動式專案設定"
        },
        {
          "cmd": "l10n translate",
          "desc": "產生翻譯"
        },
        {
          "cmd": "l10n status",
          "desc": "報告缺少或過時的輸出"
        },
        {
          "cmd": "l10n check",
          "desc": "驗證輸出語法"
        },
        {
          "cmd": "l10n clean",
          "desc": "移除過時的翻譯輸出"
        }
      ],
      "note_prefix": "使用",
      "note_suffix": "重新翻譯所有內容。"
    }
  },
  "features": {
    "title": "為實際工作流程打造",
    "items": [
      {
        "title": "上下文感知雜湊",
        "text": "當來源內容或上層 L10N.md 上下文變更時，翻譯會自動更新。"
      },
      {
        "title": "驗證 hook",
        "text": "JSON、YAML、PO 語法檢查，加上可選的外部 lint 命令。"
      },
      {
        "title": "Agent pipeline",
        "text": "協調模型和翻譯模型分離，驗證錯誤時自動重試。"
      },
      {
        "title": "人工審閱就緒",
        "text": "快速產生草稿，需要時審閱，所有內容保存在 Git 中。"
      }
    ]
  },
  "refinement": {
    "title": "漸進式優化",
    "lead": "翻譯不必在第一天就完美。就像程式碼一樣，透過迭代逐步改進。",
    "text": "LLM 的初稿在結構上是正確的，但可能遺漏細微差異、語氣或特定領域的用語。這是設計如此。每個審閱週期——一則 pull request 留言、一份更新的上下文檔案、一個術語表修正——都會回饋到下一次翻譯中。品質透過多次迭代收斂，而非一次到位。",
    "steps": [
      {
        "label": "草稿",
        "text": "LLM 根據你的上下文檔案產生結構有效的初稿。"
      },
      {
        "label": "審閱",
        "text": "團隊透過 pull request 標記問題，就像程式碼審閱一樣。"
      },
      {
        "label": "優化",
        "text": "更新的上下文和術語表修正會回饋到下一次執行，縮小差距。"
      },
      {
        "label": "收斂",
        "text": "每個週期都讓品質更接近生產水準。系統學習你產品的語調。"
      }
    ],
    "prior_art": "這遵循製造業中改善（Kaizen）、專業翻譯的譯後編輯（PEMT）、以及工程中逐次逼近法的相同原則：從足夠好的基線開始，在人工判斷的參與下系統性地改進。"
  },
  "faq": {
    "title": "常見問題",
    "items": [
      {
        "q": "這和傳統翻譯工具有什麼不同？",
        "a": "傳統工具依賴翻譯記憶庫，也就是透過相似度比對過去翻譯的靜態資料庫。l10n 以 LLM 上下文作為記憶取代它：agent 讀取、學習的上下文檔案，團隊可以隨時間迭代改進。agent 不是查找模糊比對，而是理解你產品的語氣、術語和慣例。就像開發者透過編譯或 lint 驗證程式碼變更一樣，agent 使用你環境中相同的工具驗證翻譯。在 CI 或本地執行，agent 會使用你的 linter、編譯器和驗證器來修正自己的輸出。"
      },
      {
        "q": "我需要自己準備模型嗎？",
        "a": "是的。l10n 是 CLI 工具，不是託管服務。你可以指向任何 OpenAI 相容端點、Vertex AI，或你自己的模型。成本、資料和品質都由你掌控。"
      },
      {
        "q": "人工如何審閱翻譯？",
        "a": "目前，審閱者透過 pull request 和 diff 檢查翻譯內容，需要時可更新上下文檔案強制重新翻譯。未來，我們預期他們會成為流程的一部分，在本地執行 l10n，就像開發者使用 Codex 等 coding agent 一樣。"
      }
    ]
  },
  "updates": {
    "title": "更新"
  }
}