{
  "meta": {
    "title": "l10n · ソフトウェアを出荷するようにローカライズする",
    "description": "ローカライズをリポジトリ内で管理し、既存のツールで検証し、LLMによるドラフトで素早く出荷。"
  },
  "hero": {
    "badge": "オープンソースCLIツール",
    "title": "コードベースのためのエージェント型ローカライズ",
    "lead": "l10nはLLMでコンテンツを翻訳し、すべてをリポジトリ内に保持し、出力をローカルで検証し、外部プラットフォームとのやり取りなしでチームがレビューできるドラフトを生成します。",
    "cta_primary": "始める",
    "cta_secondary": "仕組み"
  },
  "origin": {
    "title": "Tuistがこれを作った理由",
    "intro": {
      "prefix": "",
      "crowdin": "Crowdin",
      "middle": "と",
      "weblate": "Weblate",
      "suffix": "を試しました。コンテンツのエクスポートとインポートの間接的なプロセスが作業を遅くし、独自の検証をループに組み込むことができませんでした。コードと同じワークフロー、つまり変更、テスト、レビュー、出荷を求めていました。"
    },
    "note": "今では翻訳はその場で生成され、既存のツールでチェックされ、必要なときだけ人間がレビューします。"
  },
  "how": {
    "title": "仕組み",
    "steps": [
      {
        "number": "01",
        "title": "エージェントにコンテキストを与える",
        "text": "コンテンツと一緒にL10N.mdコンテキストファイルを追加します。l10nはそれらの依存関係を追跡するため、コンテキストまたはコンテンツが変更されると、影響を受ける翻訳のみが再生成されます。"
      },
      {
        "number": "02",
        "title": "モデルを選択する",
        "text": "エージェントセッションを調整するモデルと、正確に翻訳するモデルを選択します。OpenAI互換のエンドポイント、Vertex AI、または独自のホストモデルを使用できます。"
      },
      {
        "number": "03",
        "title": "エージェントが自分の作業を検証する",
        "text": "エージェントは組み込みの構文チェックと定義したカスタムコマンドにアクセスできます。翻訳ごとに検証を実行し、エラー時にリトライするため、レビュー前に出力が正しいことを確認できます。"
      }
    ]
  },
  "config": {
    "title": "設定はリポジトリ内に存在する",
    "l10n": {
      "title": "L10N.md",
      "text": "TOMLフロントマターで翻訳ソース、ターゲット、出力パターンを定義します。"
    },
    "cli": {
      "title": "CLIコマンド",
      "text": "翻訳、検証、更新が必要なものの追跡を行います。",
      "items": [
        {
          "cmd": "l10n translate",
          "desc": "翻訳を生成"
        },
        {
          "cmd": "l10n status",
          "desc": "欠落または古い出力を報告"
        },
        {
          "cmd": "l10n check",
          "desc": "出力構文を検証"
        },
        {
          "cmd": "l10n clean",
          "desc": "古い翻訳出力を削除"
        }
      ],
      "note_prefix": "",
      "note_suffix": "を使用してすべてを再翻訳します。"
    }
  },
  "features": {
    "title": "実際のワークフローのために構築",
    "items": [
      {
        "title": "コンテキスト対応のハッシュ",
        "text": "ソースコンテンツまたは祖先のL10N.mdコンテキストが変更されると翻訳が更新されます。"
      },
      {
        "title": "検証フック",
        "text": "JSON、YAML、PO構文チェックに加え、オプションで外部lintコマンドも使用可能。"
      },
      {
        "title": "エージェントパイプライン",
        "text": "コーディネーターモデルと翻訳モデルを分離し、検証エラー時にリトライ。"
      },
      {
        "title": "人間のレビューに対応",
        "text": "ドラフトを素早く生成し、必要なときにレビューし、すべてをGitに保持。"
      }
    ]
  },
  "faq": {
    "title": "FAQ",
    "items": [
      {
        "q": "従来の翻訳ツールとどう違うのですか？",
        "a": "従来のツールは翻訳メモリに依存しています。これは類似性でマッチングされる過去の翻訳の静的データベースです。l10nはこれをメモリとしてのLLMコンテキストに置き換えます。エージェントが読み、学び、チームが時間をかけて改良できるコンテキストファイルです。ファジーマッチを検索する代わりに、エージェントは製品のトーン、用語、規約を理解します。そして開発者がコンパイルやlintでコード変更を検証するように、エージェントも環境内の同じツールを使用して翻訳を検証します。CIまたはローカルで実行すると、エージェントはlinter、コンパイラ、バリデータを使用して自分の出力を修正します。"
      },
      {
        "q": "独自のモデルを用意する必要がありますか？",
        "a": "はい。l10nはCLIツールであり、ホストされたサービスではありません。OpenAI互換のエンドポイント、Vertex AI、または独自のモデルを指定します。コスト、データ、品質を自分で管理できます。"
      },
      {
        "q": "人間はどのように翻訳をレビューしますか？",
        "a": "現在、レビュアーはプルリクエストとdiffを通じて翻訳されたコンテンツを確認し、必要に応じてコンテキストファイルを更新して再翻訳を強制できます。将来的には、開発者がCodexなどのコーディングエージェントと既に行っているように、ローカルでl10nを実行することでループの一部になることを想定しています。"
      }
    ]
  },
  "updates": {
    "title": "アップデート"
  }
}