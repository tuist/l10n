{
  "meta": {
    "title": "l10n · ソフトウェアをシップするようにローカライズする",
    "description": "ローカリゼーションをリポジトリ内に保ち、既存のツールで検証し、LLMドラフトで素早くシップ。"
  },
  "hero": {
    "badge": "オープンソースCLIツール",
    "title": "コードベースのためのエージェント型ローカリゼーション",
    "lead": "l10nはLLMでコンテンツを翻訳し、すべてをリポジトリ内に保持し、出力をローカルで検証し、外部プラットフォームとのやり取りなしでチームがレビューできるドラフトを生成します。",
    "cta_primary": "はじめる",
    "cta_secondary": "仕組み"
  },
  "origin": {
    "title": "Tuistがこれを作った理由",
    "intro": {
      "prefix": "",
      "crowdin": "Crowdin",
      "middle": "と",
      "weblate": "Weblate",
      "suffix": "を試しました。コンテンツのエクスポート・インポートという間接的なプロセスがスピードを落とし、独自の検証をループに組み込むことができませんでした。コードと同じワークフローが欲しかったのです：変更、テスト、レビュー、シップ。"
    },
    "note": "今では翻訳はその場で生成され、既存のツールでチェックされ、人間のレビューは本当に必要なときだけ行われます。"
  },
  "how": {
    "title": "仕組み",
    "steps": [
      {
        "number": "01",
        "title": "エージェントにコンテキストを与える",
        "text": "コンテンツと一緒にL10N.mdコンテキストファイルを配置します。l10nはその依存関係を追跡し、コンテキストやコンテンツが変更されたときに影響を受ける翻訳だけを再生成します。"
      },
      {
        "number": "02",
        "title": "モデルを選択する",
        "text": "エージェントセッションを調整するモデルと、正確に翻訳するモデルを選びます。OpenAI互換エンドポイント、Vertex AI、または独自のホストモデルを使用できます。"
      },
      {
        "number": "03",
        "title": "エージェントが自身の作業を検証する",
        "text": "エージェントは組み込みの構文チェックとカスタムコマンドにアクセスできます。各翻訳後に検証を実行し、エラー時にリトライするため、レビュー前に出力が正しくなります。"
      }
    ]
  },
  "tools": {
    "title": "ツール",
    "intro": "エージェントはツールを使って、翻訳ごとに検証を自動化します。",
    "categories": [
      {
        "title": "構文バリデータ",
        "text": "保存前に出力をパースして有効性を確認します。",
        "items": [
          "JSON",
          "YAML",
          "PO",
          "Markdownフロントマター"
        ]
      },
      {
        "title": "保持チェック",
        "text": "重要なトークンが翻訳後も維持されることを保証します。",
        "items": [
          "コードブロック",
          "インラインコード",
          "URL",
          "プレースホルダー"
        ]
      },
      {
        "title": "カスタムコマンド",
        "text": "check_cmdとcheck_cmdsで独自のバリデータを使用できます。",
        "items": [
          "リンター",
          "コンパイラ",
          "スキーマバリデータ"
        ]
      }
    ],
    "note": "ツールが失敗すると、出力が有効になるまでリトライします。"
  },
  "config": {
    "title": "設定はリポジトリ内に存在する",
    "l10n": {
      "title": "L10N.md",
      "text": "翻訳のソース、ターゲット、出力パターンをTOMLフロントマターで定義します。"
    },
    "cli": {
      "title": "CLIコマンド",
      "text": "翻訳、検証、更新が必要なものの追跡を行います。",
      "items": [
        {
          "cmd": "l10n init",
          "desc": "インタラクティブなプロジェクトセットアップ"
        },
        {
          "cmd": "l10n translate",
          "desc": "翻訳を生成"
        },
        {
          "cmd": "l10n status",
          "desc": "不足または古い出力をレポート"
        },
        {
          "cmd": "l10n check",
          "desc": "出力の構文を検証"
        },
        {
          "cmd": "l10n clean",
          "desc": "古い翻訳出力を削除"
        }
      ],
      "note_prefix": "",
      "note_suffix": "ですべてを再翻訳できます。"
    }
  },
  "features": {
    "title": "実際のワークフローのために設計",
    "items": [
      {
        "title": "コンテキスト対応ハッシュ",
        "text": "ソースコンテンツまたは上位のL10N.mdコンテキストが変更されると翻訳が更新されます。"
      },
      {
        "title": "検証フック",
        "text": "JSON、YAML、PO構文チェックに加え、オプションで外部lintコマンドも使用可能。"
      },
      {
        "title": "エージェントパイプライン",
        "text": "コーディネーターモデルとトランスレーターモデルを分離し、検証エラー時にリトライ。"
      },
      {
        "title": "人間のレビューに対応",
        "text": "ドラフトを素早く生成し、必要なときにレビューし、すべてをGitに保持。"
      }
    ]
  },
  "refinement": {
    "title": "段階的改善",
    "lead": "翻訳は初日から完璧である必要はありません。コードと同様に、反復を通じて改善されます。",
    "text": "LLMによる初稿は構造的には正しいですが、ニュアンス、トーン、ドメイン固有の表現を見落とすことがあります。これは設計通りです。各レビューサイクル（プルリクエストのコメント、コンテキストファイルの更新、用語集の調整）が次の翻訳実行にフィードバックされます。品質は単発ではなく、連続したパスを通じて収束します。",
    "steps": [
      {
        "label": "ドラフト",
        "text": "LLMがコンテキストファイルに基づいて構造的に有効な初稿を生成。"
      },
      {
        "label": "レビュー",
        "text": "チームがコードレビューと同様に、プルリクエストを通じて問題を指摘。"
      },
      {
        "label": "改善",
        "text": "更新されたコンテキストと用語集の修正が次の実行にフィードバックされ、ギャップを埋める。"
      },
      {
        "label": "収束",
        "text": "各サイクルで本番品質との距離が縮まります。システムはあなたのプロダクトの声を学習します。"
      }
    ],
    "prior_art": "これは製造業におけるカイゼン、プロ翻訳におけるポストエディット（PEMT）、エンジニアリングにおける逐次近似と同じ原則に従っています：十分な品質のベースラインから始め、人間の判断をループに入れて体系的に改善します。"
  },
  "faq": {
    "title": "FAQ",
    "items": [
      {
        "q": "従来の翻訳ツールとの違いは？",
        "a": "従来のツールは翻訳メモリ（類似度でマッチングする過去の翻訳の静的データベース）に依存しています。l10nはこれをメモリとしてのLLMコンテキストに置き換えます：エージェントが読み、学習し、チームが時間をかけて反復できるコンテキストファイルです。ファジーマッチを検索する代わりに、エージェントはあなたのプロダクトのトーン、用語、慣習を理解します。そして開発者がコード変更をコンパイルやlintで検証するように、エージェントも同じツールを使って翻訳を検証します。CIでもローカルでも実行でき、エージェントはリンター、コンパイラ、バリデータを使って自身の出力を修正します。"
      },
      {
        "q": "独自のモデルを用意する必要がある？",
        "a": "はい。l10nはCLIツールであり、ホスト型サービスではありません。OpenAI互換エンドポイント、Vertex AI、または独自のモデルを指定します。コスト、データ、品質はあなたがコントロールします。"
      },
      {
        "q": "人間はどのように翻訳をレビューする？",
        "a": "現在、レビュアーはプルリクエストとdiffを通じて翻訳されたコンテンツをチェックし、必要に応じてコンテキストファイルを更新して再翻訳をトリガーできます。将来的には、開発者がCodexのようなコーディングエージェントを使うのと同様に、l10nをローカルで実行してループの一部になることを想定しています。"
      }
    ]
  },
  "updates": {
    "title": "更新情報"
  }
}