{
  "meta": {
    "title": "l10n · 소프트웨어 배포하듯 로컬라이즈하기",
    "description": "로컬라이제이션을 레포지토리 내에 유지하고, 기존 도구로 검증하고, LLM 초안으로 더 빠르게 배포하세요."
  },
  "hero": {
    "badge": "오픈소스 CLI 도구",
    "title": "코드베이스를 위한 에이전트 기반 로컬라이제이션",
    "lead": "l10n은 LLM으로 콘텐츠를 번역하고, 모든 것을 레포지토리 내에 유지하며, 로컬에서 출력을 검증하고, 외부 플랫폼을 거치지 않고 팀이 검토할 수 있는 초안을 생성합니다.",
    "cta_primary": "시작하기",
    "cta_secondary": "작동 방식"
  },
  "origin": {
    "title": "Tuist가 만든 이유",
    "intro": {
      "prefix": "",
      "crowdin": "Crowdin",
      "middle": "과 ",
      "weblate": "Weblate",
      "suffix": "를 써봤습니다. 콘텐츠를 내보내고 가져오는 간접적인 과정이 속도를 늦췄고, 자체 검증을 루프에 포함시킬 수 없었습니다. 코드와 동일한 워크플로를 원했습니다: 변경, 테스트, 리뷰, 배포."
    },
    "note": "이제 번역이 제자리에서 생성되고, 기존 도구로 검증되며, 필요할 때만 사람이 리뷰합니다."
  },
  "how": {
    "title": "작동 방식",
    "steps": [
      {
        "number": "01",
        "title": "에이전트에 컨텍스트 제공",
        "text": "콘텐츠와 함께 L10N.md 컨텍스트 파일을 추가하세요. l10n은 의존성을 추적하여 컨텍스트나 콘텐츠가 변경되면 영향받는 번역만 재생성합니다."
      },
      {
        "number": "02",
        "title": "모델 선택",
        "text": "에이전트 세션을 조율할 모델과 정확하게 번역할 모델을 각각 선택하세요. OpenAI 호환 엔드포인트, Vertex AI, 또는 자체 호스팅 모델을 사용할 수 있습니다."
      },
      {
        "number": "03",
        "title": "에이전트가 자체 검증 수행",
        "text": "에이전트는 내장된 구문 검사와 사용자 정의 명령에 접근할 수 있습니다. 각 번역 후 검증을 실행하고 오류 시 재시도하여, 리뷰 전에 올바른 출력을 보장합니다."
      }
    ]
  },
  "config": {
    "title": "설정은 레포지토리에 존재",
    "l10n": {
      "title": "L10N.md",
      "text": "TOML frontmatter로 번역 소스, 타겟, 출력 패턴을 정의하세요."
    },
    "cli": {
      "title": "CLI 명령어",
      "text": "번역, 검증, 업데이트 필요 항목 추적.",
      "items": [
        {
          "cmd": "l10n translate",
          "desc": "번역 생성"
        },
        {
          "cmd": "l10n status",
          "desc": "누락되거나 오래된 출력 리포트"
        },
        {
          "cmd": "l10n check",
          "desc": "출력 구문 검증"
        },
        {
          "cmd": "l10n clean",
          "desc": "오래된 번역 출력 제거"
        }
      ],
      "note_prefix": "",
      "note_suffix": "를 사용하면 전체 재번역이 가능합니다."
    }
  },
  "features": {
    "title": "실제 워크플로를 위한 설계",
    "items": [
      {
        "title": "컨텍스트 인식 해싱",
        "text": "소스 콘텐츠나 상위 L10N.md 컨텍스트가 변경되면 번역이 업데이트됩니다."
      },
      {
        "title": "검증 훅",
        "text": "JSON, YAML, PO 구문 검사와 선택적 외부 린트 명령 지원."
      },
      {
        "title": "에이전트 파이프라인",
        "text": "조율 모델과 번역 모델을 분리하고 검증 오류 시 재시도."
      },
      {
        "title": "휴먼 리뷰 대응",
        "text": "빠르게 초안을 생성하고, 필요할 때 리뷰하고, 모든 것을 Git에 유지."
      }
    ]
  },
  "faq": {
    "title": "FAQ",
    "items": [
      {
        "q": "기존 번역 도구와 어떻게 다른가요?",
        "a": "기존 도구는 번역 메모리, 즉 유사도로 매칭되는 과거 번역의 정적 데이터베이스에 의존합니다. l10n은 이를 메모리로서의 LLM 컨텍스트로 대체합니다: 에이전트가 읽고 학습하며 팀이 시간에 따라 발전시킬 수 있는 컨텍스트 파일입니다. 퍼지 매치를 찾는 대신, 에이전트가 제품의 톤, 용어, 관례를 이해합니다. 그리고 개발자가 컴파일이나 린팅으로 코드 변경을 검증하듯, 에이전트도 환경의 동일한 도구로 번역을 검증합니다. CI나 로컬에서 실행하면 에이전트가 린터, 컴파일러, 검증기를 사용해 자체 출력을 수정합니다."
      },
      {
        "q": "자체 모델을 가져와야 하나요?",
        "a": "네. l10n은 CLI 도구이지 호스팅 서비스가 아닙니다. OpenAI 호환 엔드포인트, Vertex AI, 또는 자체 모델을 지정하세요. 비용, 데이터, 품질을 직접 제어합니다."
      },
      {
        "q": "번역을 어떻게 리뷰하나요?",
        "a": "현재 리뷰어는 pull request와 diff를 통해 번역된 콘텐츠를 확인하고, 필요시 컨텍스트 파일을 수정해 재번역을 트리거할 수 있습니다. 향후에는 개발자가 Codex 같은 코딩 에이전트와 작업하듯, 로컬에서 l10n을 실행하며 루프에 참여할 것으로 예상합니다."
      }
    ]
  },
  "updates": {
    "title": "업데이트"
  }
}